{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "GeForce GTX 1660 SUPER\n",
      "P106-100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from data.MinicityDataset import TrafficDataset\n",
    "\n",
    "dbpath = '/home/rong/disk/database/minicity.db'\n",
    "bs = 12\n",
    "train_loader = DataLoader(TrafficDataset(dbpath = dbpath,\n",
    "                            train = True),\n",
    "                         batch_size = bs, shuffle=True, drop_last = True)\n",
    "test_loader = DataLoader(TrafficDataset(dbpath = dbpath,\n",
    "                            train = False),\n",
    "                          batch_size = bs, shuffle=True, drop_last = True)\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# batch['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convVAE(\n",
      "  (condnn): CondNN(\n",
      "    (cnn): Conv3d(\n",
      "      (adap_pool): AdaptiveAvgPool3d(output_size=(25, 200, 200))\n",
      "      (conv_layer1): Sequential(\n",
      "        (0): Conv3d(1, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(16, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer2): Sequential(\n",
      "        (0): Conv3d(16, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(32, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer5): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "      (adap_pool2): AdaptiveAvgPool3d(output_size=(6, 20, 20))\n",
      "    )\n",
      "    (Attention): Attention(\n",
      "      (encoder_att): Linear(in_features=67, out_features=64, bias=True)\n",
      "      (condition_att): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (full_att): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (fc1): Linear(in_features=172, out_features=300, bias=True)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=304, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (linear_means): Linear(in_features=512, out_features=50, bias=True)\n",
      "    (linear_log_var): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=350, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=512, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.minicity import convVAE\n",
    "\n",
    "X_dim = 4\n",
    "traj_size = 25 * 4\n",
    "z_dim = 50\n",
    "cnn_out_size = 300\n",
    "cond_out_size = 300\n",
    "\n",
    "model = convVAE(sample_size = X_dim, \n",
    "                  traj_size = traj_size,\n",
    "                  cnnout_size = cnn_out_size, \n",
    "                  cond_out_size = cond_out_size, \n",
    "                  encoder_layer_sizes = [512,1024,512], \n",
    "                  latent_size = z_dim, \n",
    "                  decoder_layer_sizes = [512,1024,512]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "checkpoint = torch.load('checkpoints/minicity_attention_7.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8753\n",
      "torch.Size([25, 4])\n",
      "torch.Size([25, 4])\n",
      "1276.0\n",
      "Using matplotlib backend: Qt5Agg\n",
      "[  0.         0.        -1.4532     9.86      16.669998 -20.279999\n",
      "  -0.3976    11.98    ]\n",
      "155.56666056315106 167.5999959309896\n"
     ]
    }
   ],
   "source": [
    "from utils.Minicity import plotData, plotOrientSpeed, plotAlpha\n",
    "test_data = test_loader.dataset\n",
    "viz_idx =   torch.randint(0,len(test_data),[1]).item()  \n",
    "#  变道场景idx\n",
    "viz_idx = 8753 #弯道\n",
    "# viz_idx = 143300 #弯道\n",
    "# viz_idx = 5107 #直行\n",
    "# viz_idx = 2984 #转盘\n",
    "# viz_idx = 101538 #转盘\n",
    "# viz_idx = 153309 #阻塞\n",
    "# viz_idx = 109779 #变道\n",
    "\n",
    "print(viz_idx)\n",
    "\n",
    "batch = test_data[viz_idx]\n",
    "startgoal = torch.from_numpy(batch[\"start_goal\"]).to(device)\n",
    "occ = torch.from_numpy(batch[\"observation\"])\n",
    "occ = occ[:, 200:600, 200:600]        \n",
    "occ = occ.unsqueeze(0)\n",
    "occ = occ.unsqueeze(1)\n",
    "adap_pool = nn.AdaptiveAvgPool3d((25,200, 200))\n",
    "occ = adap_pool(occ)\n",
    "occ = occ.to(device)\n",
    "traj = torch.from_numpy(batch[\"traj\"]).to(device)\n",
    "print(traj.shape)\n",
    "data = torch.from_numpy(batch[\"data\"]).to(device)\n",
    "egoid = batch[\"egoid\"]\n",
    "print(traj.shape)\n",
    "time_stamp = batch[\"timeprob\"]\n",
    "print(time_stamp)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_viz = torch.randn(1,4).to(device)\n",
    "    for i in range(0, 10):\n",
    "        num_viz = 12\n",
    "        y_viz_p, alpha = model.inference(startgoal.expand(num_viz, X_dim * 2).to(device), traj.expand(num_viz, 25, 4),\n",
    "                                occ.expand(num_viz, 1, -1, -1, -1).to(device), num_viz)\n",
    "        torch.cuda.empty_cache()\n",
    "        y_viz = torch.cat((y_viz_p, y_viz), dim = 0)\n",
    "\n",
    "y_viz=y_viz.cpu().detach().numpy()*50\n",
    "occ=occ.cpu().detach().numpy()\n",
    "startgoal=startgoal.cpu().detach().numpy() * 50\n",
    "data=data.cpu().detach().numpy() * 50\n",
    "alpha=alpha.cpu().detach().numpy()\n",
    "torch.cuda.empty_cache()\n",
    "# from utils.NarrowPassage import plotCondition, plotSample, plotSpeed, plotSampleAttention\n",
    "\n",
    "%matplotlib\n",
    "# from utils.HighWay import plotData, plotOrientSpeed, plotAlpha\n",
    "    \n",
    "y_viz=y_viz[:-1]\n",
    "plotData(occ, startgoal, y_viz)\n",
    "plotOrientSpeed(startgoal, y_viz)\n",
    "# plotAlpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAlpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68844\n",
      "[ 0.         0.        -0.         1.72       4.1299973  0.\n",
      " -0.         2.32     ]\n",
      "113.76665751139323 100.0\n"
     ]
    }
   ],
   "source": [
    "test_data = test_loader.dataset\n",
    "viz_idx =   torch.randint(0,len(test_data),[1]).item()  \n",
    "#  变道场景idx\n",
    "#  \n",
    "print(viz_idx)\n",
    "\n",
    "batch = test_data[viz_idx]\n",
    "startgoal = torch.from_numpy(batch[\"start_goal\"]).to(device)\n",
    "occ = torch.from_numpy(batch[\"observation\"])\n",
    "occ = occ[:, 200:600, 200:600]        \n",
    "occ = occ.unsqueeze(0)\n",
    "occ = occ.unsqueeze(1)\n",
    "adap_pool = nn.AdaptiveAvgPool3d((25,200, 200))\n",
    "occ = adap_pool(occ)\n",
    "# adap_pool = nn.AdaptiveAvgPool3d((25,100, 600))\n",
    "# occ = adap_pool(occ)\n",
    "occ = occ.to(device)\n",
    "data = torch.from_numpy(batch[\"data\"]).to(device)\n",
    "\n",
    "occ=occ.cpu().detach().numpy()\n",
    "startgoal=startgoal.cpu().detach().numpy() * 50\n",
    "data=data.cpu().detach().numpy() * 50\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "plotData(occ, startgoal, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# commonroad collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from commonroad.common.file_reader import CommonRoadFileReader\n",
    "from commonroad_cc.visualization.draw_dispatch import draw_object\n",
    "\n",
    "file_path = '/home/rong/VAE-Motion-Planning/scenarios/commonroad_data/minicity.cr.xml'\n",
    "# file_path = \"scenarios/commonroad_data/ZAM_Tutorial-1_2_T-1.xml\"\n",
    "# file_path = \"/home/rong/commonroad/commonroad-search-master/GSMP/tools/commonroad-road-boundary/scenarios/GER_Ffb_2.xml\"\n",
    "scenario, _ = CommonRoadFileReader(file_path).open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scenario\n",
    "plt.figure(figsize=(25, 10))\n",
    "draw_object(scenario)\n",
    "plt.autoscale()\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonroad.scenario.scenario import Scenario\n",
    "from commonroad.scenario.trajectory import State as StateTupleFactory\n",
    "from commonroad.scenario.obstacle import StaticObstacle, ObstacleType, Obstacle\n",
    "import numpy as np\n",
    "from commonroad.geometry.shape import Polygon, ShapeGroup, Circle\n",
    "from commonroad_cc.collision_detection.pycrcc_collision_dispatch import create_collision_checker, create_collision_object\n",
    "import pycrcc\n",
    "\n",
    "carcc = create_collision_checker(scenario)\n",
    "\n",
    "from scenarios.commonroad_road_boundary.construction import construct\n",
    "\n",
    "%matplotlib\n",
    "\n",
    "build = ['section_triangles']\n",
    "boundary = construct(scenario, build, ['section_triangles'], ['plot'])\n",
    "\n",
    "road_boundary_shape_list = list()\n",
    "initial_state = None\n",
    "for r in boundary['section_triangles'].unpack():\n",
    "    initial_state = StateTupleFactory(position=np.array([0, 0]), orientation=0.0, time_step=0)\n",
    "    p = Polygon(np.array(r.vertices()))\n",
    "    road_boundary_shape_list.append(p)\n",
    "road_bound = StaticObstacle(obstacle_id=scenario.generate_object_id(), obstacle_type=ObstacleType.ROAD_BOUNDARY,\n",
    "                            obstacle_shape=ShapeGroup(road_boundary_shape_list), initial_state=initial_state)\n",
    "\n",
    "roadcc = pycrcc.CollisionChecker()\n",
    "roadcc.add_collision_object(create_collision_object(road_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collision between the trajectory of the ego vehicle and objects in the environment:  False\n",
      "Collision between the trajectory of the ego vehicle and road:  True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from commonroad.scenario.trajectory import State, Trajectory\n",
    "from commonroad.prediction.prediction import TrajectoryPrediction\n",
    "from commonroad.geometry.shape import Rectangle\n",
    "from commonroad.scenario.obstacle import StaticObstacle\n",
    "from commonroad_cc.collision_detection.pycrcc_collision_dispatch import create_collision_object\n",
    "\n",
    "# # create a trajectory for the ego vehicle starting at time step 0\n",
    "time_start = 0\n",
    "position = np.array([[50, -6]])\n",
    "orientation = [0]\n",
    "state_list = list()\n",
    "for k in range(0, len(position)):\n",
    "    state_list.append(State(**{'position': position[k], 'orientation':orientation[k]}))\n",
    "trajectory = Trajectory(time_start, state_list)\n",
    "# create the shape of the ego vehicle\n",
    "shape = Rectangle(length=3.9, width=1.9)\n",
    "# # create a TrajectoryPrediction object consisting of the trajectory and the shape of the ego vehicle\n",
    "traj_pred = TrajectoryPrediction(trajectory=trajectory, shape=shape)\n",
    "# create a collision object using the trajectory prediction of the ego vehicle\n",
    "co = create_collision_object(traj_pred)\n",
    "\n",
    "# test the trajectory of the ego vehicle for collisions\n",
    "print('Collision between the trajectory of the ego vehicle and objects in the environment: ', carcc.collide(co))\n",
    "print('Collision between the trajectory of the ego vehicle and road: ', roadcc.collide(co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
