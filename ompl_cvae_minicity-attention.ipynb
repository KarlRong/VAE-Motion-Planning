{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "P106-100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sqlite3\n",
    "import torch\n",
    "import io\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.current_device()\n",
    "def adapt_array(arr):\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "def position_reformed(data, startgoal):\n",
    "    datax = (data[0]-startgoal[0])*(3/2) + startx\n",
    "    datay = (data[1]-startgoal[1])*(3/2) + starty\n",
    "    return datax, datay\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, dbpath, train=True, ratio_test=0.8, num_sce=100, num_data=25):\n",
    "        self.con = sqlite3.connect(dbpath, detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "        self.path = dbpath\n",
    "        self.cur = self.con.cursor()\n",
    "        self.cur.execute(\"select id from minicity\")\n",
    "        self.idlist = self.cur.fetchall()\n",
    "        self.cur.execute(\"select data from minicity where id = \" +  str(1))\n",
    "        self.dataperow = int(len(self.cur.fetchone()[0]) / 2)\n",
    "        numTrain = int(ratio_test * len(self.idlist))\n",
    "        if (train):\n",
    "            self.filelist = self.idlist[:numTrain]\n",
    "        else:\n",
    "            self.filelist = self.idlist[numTrain:]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.idlist) * self.dataperow\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rowid = idx // self.dataperow\n",
    "        dataid = idx % self.dataperow\n",
    "        self.cur.execute(\"select id, startgoal, occ, data, egoid from minicity where id = \" +  str(rowid+1))\n",
    "        results = self.cur.fetchone()\n",
    "        start_goal = results[1].astype(np.single)\n",
    "        observed = results[2].astype(np.single)\n",
    "        traj = results[3][0:self.dataperow].astype(np.single)\n",
    "        time_prob = results[3][self.dataperow].astype(np.single)[5]\n",
    "        data = results[3][self.dataperow + dataid].astype(np.single)\n",
    "        egoid = results[4]\n",
    "        \n",
    "        start_goal[4] = start_goal[4] - start_goal[0]\n",
    "        start_goal[5] = start_goal[5] - start_goal[1]\n",
    "        \n",
    "        traj[:, 0] = traj[:, 0] - start_goal[0]\n",
    "        traj[:, 1] = traj[:, 1] - start_goal[1]\n",
    "        data[0] = data[0] - start_goal[0]\n",
    "        data[1] = data[1] - start_goal[1]\n",
    "        traj = traj[:,0:4]/50\n",
    "        data = data[0:4]/50\n",
    "        \n",
    "        for i in range(0, int(len(observed)/2)):\n",
    "            observed[i, :] = observed[2*i, :, ]\n",
    "        \n",
    "        observed = observed[0:int(len(observed)/2), :]\n",
    "        start_goal[0] = 0\n",
    "        start_goal[1] = 0\n",
    "        start_goal = start_goal/50\n",
    "        \n",
    "        sample = {'start_goal': start_goal,\n",
    "                              'traj': traj,\n",
    "                             'observation': observed,\n",
    "                             'data': data,\n",
    "                             'egoid': egoid,\n",
    "                             'timeprob':time_prob}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dbpath = '/home/rong/disk/database/minicity.db'\n",
    "bs = 12\n",
    "train_loader = DataLoader(TrafficDataset(dbpath = dbpath,\n",
    "                            train = True),\n",
    "                         batch_size = bs, shuffle=True, drop_last = True)\n",
    "test_loader = DataLoader(TrafficDataset(dbpath = dbpath,\n",
    "                            train = False),\n",
    "                          batch_size = bs, shuffle=True, drop_last = True)\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# batch['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "class convVAE(nn.Module):\n",
    "    def __init__(self, sample_size, traj_size, cnnout_size, cond_out_size, encoder_layer_sizes, latent_size, decoder_layer_sizes):\n",
    "        super(convVAE, self).__init__()\n",
    "\n",
    "        assert type(encoder_layer_sizes) == list\n",
    "        assert type(latent_size) == int\n",
    "        assert type(decoder_layer_sizes) == list\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.condnn = CondNN(sample_size, traj_size, cnnout_size)\n",
    "        self.encoder = Encoder(sample_size + cond_out_size, encoder_layer_sizes, latent_size)\n",
    "        self.decoder = Decoder(latent_size +cond_out_size, decoder_layer_sizes, sample_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x, startend, traj, occ):\n",
    "        c, _= self.condnn(startend, traj, occ)\n",
    "#         print(\"x size: \", x.shape)\n",
    "#         print(\"c size\", c.shape)\n",
    "        mu, logvar = self.encode(torch.cat((x, c), dim=1))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(torch.cat((z, c), dim=-1)), mu, logvar\n",
    "    \n",
    "    def inference(self, startend, traj, occ, num_viz):\n",
    "        c, alpha = self.condnn(startend, traj, occ)\n",
    "        z = torch.randn(num_viz, self.latent_size, device = c.device)\n",
    "        return self.decode(torch.cat((z, c), dim=-1)), alpha\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        modules = []\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            modules.append(nn.Linear(in_size, out_size))\n",
    "            modules.append(nn.ReLU())\n",
    "#             modules.append(nn.Dropout(p=0.5))\n",
    "\n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        means = self.linear_means(x)\n",
    "        log_vars = self.linear_log_var(x)\n",
    "        return means, log_vars\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes, sample_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        modules = []\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            modules.append(nn.Linear(in_size, out_size))\n",
    "            modules.append(nn.ReLU())\n",
    "#             modules.append(nn.Dropout(p=0.5))\n",
    "        modules.append(nn.Linear(layer_sizes[-1], sample_size))\n",
    "\n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class CondNN(nn.Module):\n",
    "    def __init__(self, sampleSize, traj_size, outSize, encoder_dim=64, attention_dim=64):\n",
    "        super(CondNN, self).__init__()\n",
    "        self.sampleSize = sampleSize\n",
    "        self.cnn = Conv3d(cnn_out_size)\n",
    "        self.Attention = Attention(cnn_encode_dim=encoder_dim, condition_dim=sampleSize * 2, attention_dim=attention_dim) # + 3 for position\n",
    "        self.fc1 = nn.Linear(encoder_dim + sampleSize * 2 + traj_size, outSize)\n",
    "\n",
    "    def forward(self, startend, traj, occ):\n",
    "        cnn_encode = self.cnn(occ)\n",
    "        batch_size = startend.size(0)\n",
    "        attention_weighted_encoding, alpha = self.Attention(cnn_encode, startend)\n",
    "        x = torch.cat((attention_weighted_encoding, startend, traj.view(batch_size, -1)), dim=-1)\n",
    "#         print(\"condnn cated size:\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        return x, alpha\n",
    "\n",
    "class Conv3d(nn.Module):\n",
    "    def __init__(self, cnn_out_size):\n",
    "        super(Conv3d, self).__init__()\n",
    "\n",
    "        self.adap_pool = nn.AdaptiveAvgPool3d((25, 200, 200))\n",
    "        self.conv_layer1 = self._make_conv_layer(1, 16)\n",
    "        self.conv_layer2 = self._make_conv_layer(16, 32)\n",
    "#         self.conv_layer3 = self._make_conv_layer(64, 124)\n",
    "        self.conv_layer5=nn.Conv3d(32, 64, kernel_size=(1, 3, 3), padding=0)\n",
    "        \n",
    "        self.adap_pool2 = nn.AdaptiveAvgPool3d((6, 20, 20))\n",
    "\n",
    "    def _make_conv_layer(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv3d(in_c, out_c, kernel_size=(2, 3, 3), padding=0),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv3d(out_c, out_c, kernel_size=(2, 3, 3), padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.adap_pool(x)\n",
    "#         print(x.size())\n",
    "        x = self.conv_layer1(x)\n",
    "#         print(x.size())\n",
    "        x = self.conv_layer2(x)\n",
    "#         print(x.size())\n",
    "        x=self.conv_layer5(x)\n",
    "#         print(x.size())\n",
    "        x = self.adap_pool2(x)\n",
    "#         print(\"cnn out size\",x.size())\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, cnn_encode_dim, condition_dim, attention_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(cnn_encode_dim + 3, attention_dim) #位置信息\n",
    "        self.condition_att = nn.Linear(condition_dim, attention_dim)\n",
    "        self.full_att = nn.Linear(attention_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.position = self.initPosition()\n",
    "    \n",
    "    def initPosition(self):\n",
    "        x = np.linspace(0, 5, 6, dtype='float32')\n",
    "        y = np.linspace(0, 19, 20, dtype='float32')\n",
    "        t = np.linspace(0, 19, 20, dtype='float32')\n",
    "        tv,xv, yv = np.meshgrid(t,x,y)\n",
    "        xv, yv, tv = xv.reshape((1,-1, 1)), yv.reshape((1,-1, 1)), tv.reshape((1,-1, 1))\n",
    "        position = torch.from_numpy(np.concatenate((xv, yv, tv), axis = 2))\n",
    "        \n",
    "        return position\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_out, condition):\n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(1)      \n",
    "        encoder_out = encoder_out.permute(0, 2, 3, 4, 1)\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        self.position = self.position.to(encoder_out.device)\n",
    "        \n",
    "        self.position = self.position.expand(batch_size, self.position.shape[1], self.position.shape[2]) #存疑\n",
    "        encoder_out_pos = torch.cat((encoder_out, self.position), dim = 2)\n",
    "#         print(\"cat encoder_out: \", encoder_out_pos.shape)\n",
    "        att1 = self.encoder_att(encoder_out_pos)\n",
    "        att2 = self.condition_att(condition)# 依然不清晰\n",
    "        att2 = att2.unsqueeze(1)\n",
    "        att2 = att2.expand(batch_size, att1.shape[1], -1)\n",
    "#         print(\"att1: \", att1.shape)\n",
    "#         print(\"att2: \", att2.shape)\n",
    "        \n",
    "        att = self.relu(self.full_att(att1 + att2))\n",
    "#         print(\"att: \", att.shape)\n",
    "        \n",
    "        alpha = self.softmax(att)\n",
    "#         print(\"encoder_out: \", encoder_out.shape)\n",
    "#         print(\"alpha shape: \", alpha.shape)\n",
    "        attention_weighted_encoding = (encoder_out * alpha).sum(dim=1)\n",
    "#         print(\"attention_weighted_encoding: \", attention_weighted_encoding.shape)\n",
    "            \n",
    "        return attention_weighted_encoding, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "convVAE(\n",
      "  (condnn): CondNN(\n",
      "    (cnn): Conv3d(\n",
      "      (adap_pool): AdaptiveAvgPool3d(output_size=(25, 200, 200))\n",
      "      (conv_layer1): Sequential(\n",
      "        (0): Conv3d(1, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(16, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer2): Sequential(\n",
      "        (0): Conv3d(16, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(32, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer5): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "      (adap_pool2): AdaptiveAvgPool3d(output_size=(6, 20, 20))\n",
      "    )\n",
      "    (Attention): Attention(\n",
      "      (encoder_att): Linear(in_features=67, out_features=64, bias=True)\n",
      "      (condition_att): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (full_att): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (fc1): Linear(in_features=172, out_features=300, bias=True)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=304, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (linear_means): Linear(in_features=512, out_features=50, bias=True)\n",
      "    (linear_log_var): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=350, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=512, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "X_dim = 4\n",
    "traj_size = 25 * 4\n",
    "z_dim = 50\n",
    "cnn_out_size = 300\n",
    "cond_out_size = 300\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "model = convVAE(sample_size = X_dim, \n",
    "                  traj_size = traj_size,\n",
    "                  cnnout_size = cnn_out_size, \n",
    "                  cond_out_size = cond_out_size, \n",
    "                  encoder_layer_sizes = [512,1024,512], \n",
    "                  latent_size = z_dim, \n",
    "                  decoder_layer_sizes = [512,1024,512]).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, w, mean, log_var):\n",
    "    MSE = torch.mean((w.expand_as(x) * (recon_x-x)**2))\n",
    "    KLD = - 0.0005 * torch.mean(torch.sum(1 + log_var - mean.pow(2) - log_var.exp(), 1))\n",
    "    return MSE + KLD, MSE\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, writer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    mse_loss = 0\n",
    "    w = torch.tensor([8, 10, 2, 3], dtype=torch.float).to(device)\n",
    "    adap_pool = nn.AdaptiveAvgPool3d((25,200, 200))\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        startgoal = batch[\"start_goal\"].to(device)\n",
    "        occ = batch[\"observation\"]\n",
    "        occ = occ[:, :, 200:600, 200:600]        \n",
    "        occ = adap_pool(occ)\n",
    "        occ = occ.to(device)\n",
    "        occ = occ.unsqueeze(1)\n",
    "        data = batch[\"data\"].to(device)\n",
    "        traj = batch[\"traj\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data, startgoal, traj,  occ)\n",
    "        loss, mse= loss_fn(recon_batch, data, w, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        mse_loss += mse.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item()))\n",
    "        \n",
    "            writer.add_scalar('BatchLoss/loss', loss.item(), batch_idx)\n",
    "            writer.add_scalar('BatchLoss/mse_loss', mse.item(), batch_idx)\n",
    "\n",
    "    epoch_loss = train_loss * len(data) / len(train_loader.dataset)\n",
    "    epoch_mse = mse_loss * len(data) / len(train_loader.dataset)\n",
    "    print('====> Epoch: {} Average loss: {:.7f}'.format(\n",
    "          epoch, epoch_loss))\n",
    "    return epoch, epoch_loss, epoch_mse\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    mse_loss = 0\n",
    "    w = torch.tensor([8, 10, 2, 3], dtype=torch.float).to(device)\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        startgoal = batch[\"start_goal\"].to(device)\n",
    "        occ = batch[\"observation\"].to(device)\n",
    "        occ = occ.unsqueeze(1)\n",
    "        data = batch[\"data\"].to(device)\n",
    "        \n",
    "        recon_batch, mu, logvar = model(sample, startend, occ)\n",
    "        loss, mse= loss_fn(recon_batch, data, w, mu, logvar)\n",
    "        test_loss += loss.item()\n",
    "        mse_loss += mse.item()\n",
    "\n",
    "    epoch_loss = test_loss * len(data) / len(test_loader.dataset)\n",
    "    epoch_mse = mse_loss * len(data) / len(test_loader.dataset)\n",
    "    print('====> Epoch: {} Average test loss: {:.7f}'.format(\n",
    "          epoch, epoch_loss))\n",
    "    return epoch, epoch_loss, epoch_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter('runs/minicity_attention_7_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/210000 (0%)]\tLoss: 0.070153\n",
      "Train Epoch: 0 [240/210000 (0%)]\tLoss: 0.056549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af950977bd11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     vis.line(X=torch.ones((1,1)).cpu()*epoch,Y=torch.Tensor([epoch_loss]).unsqueeze(0).cpu(),win=loss_window,update='append',name='loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         vis.line(X=torch.ones((1,1)).cpu()*epoch,Y=torch.Tensor([epoch_mse]).unsqueeze(0).cpu(),win=loss_window,update='append',name='mse_loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-54408ddc8b4b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, writer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0madap_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mstartgoal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_goal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mocc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-18cd0a96326f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mrowid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataperow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdataid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataperow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select id, startgoal, occ, data, egoid from minicity where id = \"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mstart_goal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-18cd0a96326f>\u001b[0m in \u001b[0;36mconvert_array\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch, epoch + 200):\n",
    "    log_interval = 20\n",
    "    epoch, epoch_loss, epoch_mse = train(epoch, writer)\n",
    "#     vis.line(X=torch.ones((1,1)).cpu()*epoch,Y=torch.Tensor([epoch_loss]).unsqueeze(0).cpu(),win=loss_window,update='append',name='loss')\n",
    "#         vis.line(X=torch.ones((1,1)).cpu()*epoch,Y=torch.Tensor([epoch_mse]).unsqueeze(0).cpu(),win=loss_window,update='append',name='mse_loss')\n",
    "    writer.add_scalar('Loss/loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('Loss/mse_loss', epoch_mse, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, 'checkpoints/minicity_attention_7.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "convVAE(\n",
      "  (condnn): CondNN(\n",
      "    (cnn): Conv3d(\n",
      "      (adap_pool): AdaptiveAvgPool3d(output_size=(25, 200, 200))\n",
      "      (conv_layer1): Sequential(\n",
      "        (0): Conv3d(1, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(16, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer2): Sequential(\n",
      "        (0): Conv3d(16, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): Conv3d(32, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_layer5): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "      (adap_pool2): AdaptiveAvgPool3d(output_size=(6, 20, 20))\n",
      "    )\n",
      "    (Attention): Attention(\n",
      "      (encoder_att): Linear(in_features=67, out_features=64, bias=True)\n",
      "      (condition_att): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (full_att): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (fc1): Linear(in_features=172, out_features=300, bias=True)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=304, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (linear_means): Linear(in_features=512, out_features=50, bias=True)\n",
      "    (linear_log_var): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=350, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=512, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "model = convVAE(sample_size = X_dim, \n",
    "                  traj_size = traj_size,\n",
    "                  cnnout_size = cnn_out_size, \n",
    "                  cond_out_size = cond_out_size, \n",
    "                  encoder_layer_sizes = [512,1024,512], \n",
    "                  latent_size = z_dim, \n",
    "                  decoder_layer_sizes = [512,1024,512]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "checkpoint = torch.load('checkpoints/minicity_attention_7.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64486\n",
      "torch.Size([25, 4])\n",
      "Using matplotlib backend: Qt5Agg\n",
      "[ 0.         0.        -3.1416     5.74      -8.9        5.1799927\n",
      " -4.2487     5.73     ]\n",
      "70.33333460489908 82.73335774739583\n"
     ]
    }
   ],
   "source": [
    "test_data = test_loader.dataset\n",
    "viz_idx =   torch.randint(0,len(test_data),[1]).item()  \n",
    "#  变道场景idx\n",
    "# viz_idx = 8753 弯道\n",
    "# viz_idx = 143300 弯道\n",
    "# viz_idx = 5107 直行\n",
    "# viz_idx = 2984 转盘\n",
    "# viz_idx = 101538 转盘\n",
    "# viz_idx = 153309 阻塞\n",
    "# viz_idx = 109779 变道\n",
    "\n",
    "print(viz_idx)\n",
    "\n",
    "batch = test_data[viz_idx]\n",
    "startgoal = torch.from_numpy(batch[\"start_goal\"]).to(device)\n",
    "occ = torch.from_numpy(batch[\"observation\"])\n",
    "occ = occ[:, 200:600, 200:600]        \n",
    "occ = occ.unsqueeze(0)\n",
    "occ = occ.unsqueeze(1)\n",
    "adap_pool = nn.AdaptiveAvgPool3d((25,200, 200))\n",
    "occ = adap_pool(occ)\n",
    "occ = occ.to(device)\n",
    "traj = torch.from_numpy(batch[\"traj\"]).to(device)\n",
    "print(traj.shape)\n",
    "data = torch.from_numpy(batch[\"data\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_viz = torch.randn(1,4).to(device)\n",
    "    for i in range(0, 10):\n",
    "        num_viz = 8\n",
    "        y_viz_p, alpha = model.inference(startgoal.expand(num_viz, X_dim * 2).to(device), traj.expand(num_viz, 25, 4),\n",
    "                                occ.expand(num_viz, 1, -1, -1, -1).to(device), num_viz)\n",
    "        torch.cuda.empty_cache()\n",
    "        y_viz = torch.cat((y_viz_p, y_viz), dim = 0)\n",
    "\n",
    "y_viz=y_viz.cpu().detach().numpy()*50\n",
    "occ=occ.cpu().detach().numpy()\n",
    "startgoal=startgoal.cpu().detach().numpy() * 50\n",
    "data=data.cpu().detach().numpy() * 50\n",
    "alpha=alpha.cpu().detach().numpy()\n",
    "torch.cuda.empty_cache()\n",
    "# from utils.NarrowPassage import plotCondition, plotSample, plotSpeed, plotSampleAttention\n",
    "\n",
    "%matplotlib\n",
    "# from utils.HighWay import plotData, plotOrientSpeed, plotAlpha\n",
    "    \n",
    "y_viz=y_viz[:-1]\n",
    "plotData(occ, startgoal, y_viz)\n",
    "plotOrientSpeed(startgoal, y_viz)\n",
    "# plotAlpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAlpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "startx = 100\n",
    "starty = 100\n",
    "\n",
    "def position2imagep(data, startgoal):\n",
    "    datax = (data[0])*(10/3) + 100\n",
    "    datay = 100-(data[1])*(10/3) \n",
    "    return datax, datay\n",
    "\n",
    "def plotCondition(occ, startgoal):\n",
    "    fig = plt.figure()\n",
    "    occ=occ.squeeze(0)\n",
    "    occ=occ.squeeze(0)\n",
    "    myobj = plt.imshow(occ[0, :, :])\n",
    "    goalx, goaly = position2imagep(startgoal[4:], startgoal)\n",
    "    plt.scatter(startx, starty)\n",
    "    plt.scatter(goalx, goaly)\n",
    "    for frame in occ:\n",
    "        myobj.set_data(frame)\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "def plotData(occ, startgoal,data):\n",
    "    fig = plt.figure()\n",
    "    occ=occ.squeeze(0)\n",
    "    occ=occ.squeeze(0)\n",
    "    myobj = plt.imshow(occ[0, :, :])\n",
    "    goalx, goaly = position2imagep(startgoal[4:], startgoal)\n",
    "    print(startgoal)\n",
    "    print(goalx, goaly)\n",
    "    plt.scatter(startx, starty)\n",
    "    plt.scatter(goalx, goaly)\n",
    "    if len(data.shape) > 1:\n",
    "        for row in data:\n",
    "            datax, datay = position2imagep(row, startgoal)\n",
    "            plt.scatter(datax, datay, marker='*', c='#d62728')\n",
    "    else:\n",
    "        datax, datay = position2imagep(data, startgoal)\n",
    "        plt.scatter(datax, datay, marker='*', c='#d62728')\n",
    "    for frame in occ:\n",
    "        myobj.set_data(frame)\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "def plotOrientSpeed(startgoal, data):\n",
    "    fig = plt.figure()\n",
    "    goalx, goaly = position2imagep(startgoal[4:], startgoal)\n",
    "    plt.scatter(data[:, 2], data[:,3])\n",
    "    plt.scatter(startgoal[2], startgoal[3])\n",
    "    plt.scatter(startgoal[6], startgoal[7])\n",
    "    \n",
    "def plotAlpha(alpha):\n",
    "    fig = plt.figure()\n",
    "    alpha = alpha[0,:]\n",
    "    alpha=alpha.reshape(6,20,20)\n",
    "    \n",
    "    myobj = plt.imshow(alpha[0, :, :])\n",
    "\n",
    "    for frame in alpha:\n",
    "        myobj.set_data(frame)\n",
    "        plt.draw()\n",
    "        plt.pause(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445954\n"
     ]
    }
   ],
   "source": [
    "test_data = test_loader.dataset\n",
    "viz_idx =   torch.randint(0,len(test_data),[1]).item()  \n",
    "#  变道场景idx\n",
    "#  \n",
    "print(viz_idx)\n",
    "\n",
    "batch = test_data[viz_idx]\n",
    "startgoal = torch.from_numpy(batch[\"start_goal\"]).to(device)\n",
    "occ = torch.from_numpy(batch[\"observation\"])\n",
    "occ = occ.unsqueeze(0)\n",
    "occ = occ.unsqueeze(1)\n",
    "# adap_pool = nn.AdaptiveAvgPool3d((25,100, 600))\n",
    "# occ = adap_pool(occ)\n",
    "occ = occ.to(device)\n",
    "data = torch.from_numpy(batch[\"data\"]).to(device)\n",
    "\n",
    "occ=occ.cpu().detach().numpy()\n",
    "startgoal=startgoal.cpu().detach().numpy()\n",
    "data=data.cpu().detach().numpy()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "plotData(occ, startgoal, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 25, 300, 1853)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
